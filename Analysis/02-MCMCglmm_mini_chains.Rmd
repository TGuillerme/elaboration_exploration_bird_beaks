---
title: "Bird beak's elaboration and exploration"
author: "Thomas Guillerme"
date: "`r Sys.Date()`"
bibliography: references.bib
output:
  html_document:
    fig_width: 8
    fig_height: 8
---

All the custom code and custom functions called in this document can be downloaded and installed in `R` as the standalone working package `beer` (Beak Elaboration and Exploration in R).
Although `beer` is intentionally designed to be portable and shareable, we advise workers to use it with moderation and tailor its consumption to their specific research needs.
Some analyses in `beer` do take some time to run so we advise you do not operate heavy machinery while using it.
Don't use it while driving.
The following code snippets are used to illustrate the implementation of the functions.
See <!-- §§§run_replicates_script --> for running the actual analyses.


```{r install_beer, eval = FALSE}
## Installing beer
devtools::install_github("TGuillerme/elaboration_exploration_bird_beaks/beer")
```

```{r load_beer, eval = TRUE, message = FALSE}
set.seed(42)
## Loading beer
library(mcmcmcglmmm)
library(MCMCglmm)
library(dispRity)

## Loading the parametrisation data
load(file = "../Data/Processed/form_shape_space_1tree_2levels.rda")

## Select the data
shapespace <- form_shape_space_1tree_2levels$shape_space
groups_list <- form_shape_space_1tree_2levels$groups_list
selected_dim <- form_shape_space_1tree_2levels$shape_dim
consensus_tree <- form_shape_space_1tree_2levels$consensus_tree

```

# MCMCglmm mini chains analyses

To estimate the variance-covariance matrix for the phylogeny and each clade (see [01-Data_preparation.Rmd](01-Data_preparation.Rmd)) we run multivariate generalised linear mixed models (MCMCglmm) using the `MCMCglmm` package [@MCMCglmm].

## Model

We ran a general multi-response model with `§§§N_traits` of the trait space as fixed effects (using a Gaussian distribution) and and the residual covariance structure.
We used `§§§N_clades + 1` random effects (one for the whole phylogeny and one for each clade).
<!-- % NC: I know this is in the data prep, but can you specify an example MCMCglmm model here to make it clearer what you mean? -->

## Mini chains

To increase the speed of the analysis and take phylogenetic uncertainty into account, we used a "mini chains" approach.
It runs multiple MCMCglmm analyses on multiple trees and pulls the results together into one larger MCMCglmm that contains more variation due to phylogenetic uncertainty (similar to @mulTree - ADD LINK?).
The size of the chains are optimised for speed. <!-- % NC: Editted as multree is not familiar to everyone, so keeping it general and linking to multree is better -->

### Mini-chains parametrization

We first ran three independent MCMC chains with the model and data described above using the consensus tree and flat priors.
We ran these models (for `§§§N_generations` sampling every `§§§N_nitt` with no burnin) until the three chains reached an effective sample size >> 200 (§§§and other diagnosis). 
<!-- % NC: I thought in MCMCglmm the nitt parameter was total number of iterations, and thin gives how often the chain is sampled? I think you've called nitt generations here but better to be consistent with MCMCglmm?
 -->
 
```{r, parametrise_the_model, eval = FALSE}
## Set up the parametrising chains models
param_MCMCglmm <- make.mini.chains(data         = shapespace,
                                   dimensions   = selected_dim,
                                   tree         = consensus_tree,
                                   trait.family = "gaussian",
                                   randoms      = c("global", "level1", "level2"),
                                   residuals    = "global",
                                   priors       = 0.02,
                                   verbose      = TRUE,
                                   parameters   = list(
                                       nitt   = 20000,
                                       thin   = 500,
                                       burnin = 0))

## Running the three MCMCglmm models
100k_params_shapespace_8D_31levels <- run.mini.chains(param_MCMCglmm, replicates = 1)
save(param_chains, file = "../Data/Processed/MCMCglmm/100k_params_shapespace_8D_31levels_chain1.rda")
```

From these three chains, we first extracted the three burnin periods (defined as the generation when the chain reaches the median likelihood value times 1.25).
We then extracted the posterior estimates of the R-Structure, G-Structure and fixed effects (mean and covariance) (ignoring the runs from the previously estimated burnin periods) to serve as our priors for our mini-chains. 
For those values, we took the highest burnin as the overall burnin and the median of the three posteriors as the overall priors.

```{r, get_model_parameters, eval = FALSE}
## Load the computed models
param_chains <- list()
for(i in 1:3) {
    load(paste0("../Data/Cluster/allbirds_8748t_8Dshapespace_31levels/param_chains/params_shapespace_8D_31levels_20k_chain", i, ".rda"))
    param_chains[[i]] <- params_shapespace_8D_31levels[[1]]
}
## Extract the parameters from the parameter chains
est_params <- extract.parameters(param_chains)
```

### Running the mini-chains

We set up a mini-chain to be a MCMCglmm running with 1) the model described above, 2) a random tree, and 3) the estimated priors (with a degree of parameter belief of 5% `nu = 0.05`) to run for `nitt` generations were `nitt` is equal to the previously estimated burnin phase + 100 sampled iterations (`nitt = burnin + thin * 100`).
Each mini-chain thus provided us with 100 posterior data points.
The two main advantages of this mini-chain approach is that 1) they are much faster to run since no diagnosis of convergence is necessary and the chains are only run for a relatively short time (which allow several chains to crash/fail without losing all the outputs); and 2) they take into account tree uncertainty without having to run the complete MCMCglmm on all trees (c.f. @mulTree).


```{r, set_the_mini_chains, eval = TRUE}
## Get the distribution of trees
load(file = "../Data/Processed/trees_list.rda")

## The thinning parameter
thin <- 200
## The number of samples per chains
samples <- 10

## Set up the mini-chains models
shapespace_8748t_8D_32level <- make.mini.chains(
                                data         = shapespace,
                                dimensions   = selected_dim,
                                tree         = trees_list[sample(1:1000, 20)],
                                trait.family = "gaussian",
                                randoms      = c("global", "level1", "level2"),
                                residuals    = "global",
                                priors       = est_params$priors,
                                verbose      = TRUE,
                                parameters   = list(
                                    nitt   = est_params$burnin + thin * samples,
                                    thin   = thin,
                                    burnin = est_params$burnin))
## Save the mini.chains
save(shapespace_8748t_8D_32level, file = "../Data/Cluster/allbirds_8748t_8Dshapespace_31levels/shapespace_8748t_8D_32level.mini.chains")
```

We then run the MCMCglmm over $N_trees$ to get an estimate of the variance-covariance matrices including phylogenetic uncertainty.

```{r, running_replicates, eval = FALSE}
## The number of replicates
n_reps <- 10

## Run the required chains
results <- run.mini.chains(mini_chains, replicates = n_reps, path = "../Data/Processed/MCMC/")

## Combining the results as one big MCMC
combined_results <- combine.mini.chains(results)

## Saving the results
save(combined_results, file = "../Data/processed/combined_results.rda")
```



<!-- 

#### Number of runs optimisation (TO BE DEVELOPED?)

```{r, eval = FALSE}
## Function for running one mini chain on a random tree (and saving the results)
fun.mini.chains <- function() {
    run.mini.chains(mini_chains, replicates = 1, path = "../Data/Processed/MCMC/", file.name = "mini.chains")
}
```

To make sure we reached consistent results, we run the set of N mini-chains were N was determined using the following variance optimisation algorithm.
 
 * 1. run an initial $N = 20$ chains;
 * 2. estimate the $V_{1}$, the pooled variances for each parameters in the chain (V1 is a vector of length §§§);
 * 3. update N to N = N * 1.05 and run an additional 5% chains;
 * 4. estimate $V_{2}$, the pooled variances for each parameters in the chain;
 * 5. calculate $\Delta_V$, the absolute change between $V_{1}$ and $V_{2}$ as ($\sqrt{(\frac{V_{1}}/{V_{2}} - 1)^{2}}$).
 * 6. If $\Delta_V < 0.05$ (meaning an increase of 5% of the replicates resulted in an increase of the parameters of less than 5%), the desired number of mini-chains is reached. Else, set $V_{1} = V_{2}$ and repeat from step 3.


```{r, optimised_replicates, eval = FALSE}
## The summary function

```


After reaching the desired $N$ chains, we pulled all the posterior estimates together back into a "standard" big MCMCglmm with a posterior distribution including the effective results and the phylogenetic uncertainty.

-->

## References
