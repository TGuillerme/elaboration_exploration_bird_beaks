---
title: "mini chains MCMCglmm method"
author: "Thomas Guillerme"
date: "`r Sys.Date()`"
bibliography: references.bib
output:
  html_document:
    fig_width: 8
    fig_height: 8
---

```{r, echo = FALSE}
## For a fancy vignette
library(knitr)
```

This vignette explains the details of how the mini chains MCMCglmm method works and how to use it's implementation in the `mcmcmcglmmm` package.
Note that this method is entirely based on Jarrod Hadfield's [`MCMCglmm` package](https://cran.r-project.org/web/packages/MCMCglmm/index.html) which fits multivariate generalised linear mixed models using markov chain monte carlo techniques [@hadfield2010]. 
The `MCMCglmm` method **will not be explained in details here**.
If you need to know more about this method, please refer to the excellent vignettes provided by the `MCMCglmm` package (a brief [overview](https://cran.r-project.org/web/packages/MCMCglmm/vignettes/Overview.pdf) and a more advanced set of [course notes](https://cran.r-project.org/web/packages/MCMCglmm/vignettes/CourseNotes.pdf)).

## Installation and requirements

To install the `mcmcmcglmmm` package, you can do it by directly downloading the latest version on GitHub using `devtools`:

```{r install_mcmcmcglmmm, eval = FALSE}
## Installing mcmcmcglmmm
devtools::install_github("TGuillerme/elaboration_exploration_bird_beaks/mcmcmcglmmm")
```

It also relies on the latest version of the `dispRity` package (>=1.6.8) for some specific background functions.
The package will automatically install the latest version of `MCMCglmm` and `dispRity`.

```{r load_mcmcmcglmmm, eval = TRUE, message = FALSE}
set.seed(42)
## Loading mcmcmcglmmm
library(mcmcmcglmmm)

## Loading the demo data and trees
data(demo_data)
data(demo_tree)
```

The data loaded by `demo_data` and `demo_tree` is a small dataset from @cooney2017.
It contains 55 species data frame containing 5 dimensions, species names and clade names and one corresponding phylogenetic tree for the 55 species. 

Here is what the dataset looks like:

```{r, echo = FALSE}
kable(head(demo_data))
```
Note that the `"animal"` column is required for `MCMCglmm` (but please refer to the function manuals referenced above for more details).

And here's what the tree looks like:

```{r, echo = FALSE}
plot(ladderize(demo_tree), cex = 0.5)
```

### Using your own data

For simplicity further down the line, or if you want to follow this vignette with your own data, we are going to name the `demo_data` `trait_space` (here an ordinated morphospace) and create a list of three `demo_tree` (that are identical) to demonstrate how `mcmcmcglmmm` works on multiple trees.
Feel free to replace `demo_data` and `demo_tree` in the following snippet by your own data for more fun (the result of the tutorial will use the object names `trait_space` `consensus_tree` and `trees_list`).

```{r, eval = TRUE}
## Renaming the data
trait_space <- demo_data
consensus_tree <- demo_tree
trees_list <- list(demo_tree, demo_tree, demo_tree)
class(trees_list) <- "multiPhylo"
```

# The mini chains MCMCglmm method

To estimate the variance-covariance matrix for the phylogeny and each clade we run multivariate generalised linear mixed models (MCMCglmm) using the `MCMCglmm` package [@hadfield2010].

## The model

For this demo, we are going to use a mixed model with two nested random levels, one for the whole phylogeny and one for each different clade on our response variable: the first 3 PC axes from the trait space.
In brief the model we're using has the following structure:

> model = traits + random terms + residuals terms

Where `traits` is the 3 dimensional ordination values for each species, `random terms` are the two nested phylogenetic effects and `residuals` are the residuals on the dataset. In `MCMCglmm` pseudo code, the model looks like this (for each `formula`, `random` and `residuals` arguments):

```
formula   = PC1:8 ~ trait:clade-1
random    = ~ us(at.level(clade):trait):animal + us(trait):animal
residuals = ~ us(trait):units
```

In this demo case, the model would actually run pretty fast on each of the demo trees.
If you have a small dataset like presented here, you might be interested in looking at the older `mulTree` [@mulTree] method that will simply run this model on the three trees in a parallelisable way.

## `mcmcmcglmmm`

However, on much larger datasets, this becomes very quickly untractable computationally.
For example, for a dataset of  8 dimensions, 8k species and 3 nested levels it takes approximately 2 weeks and a whopping 512 GB of RAM to barely get results for one tree!

Thus, to increase the speed of these analyses, while taking phylogenetic uncertainty into account, we used a highly parallelisable "mini chains" approach.
In brief, it runs multiple short `MCMCglmm` analyses on multiple trees and pulls the results together into one larger `MCMCglmm` that contains more variation due to phylogenetic uncertainty (where the size of the chains are optimised for speed and low RAM usage).

[mini chain diagram](mini-chains_diagram.png "Mini chains diagram")

The method works as follows:
 
 1- run three models without burnin on a consensus tree with flat priors: these are the parametrisation chains.
 
 2- extract the burnin length and the posteriors to be used as priors from the parametrisation chains.
 
 3- run multiple models with 10 samplings past the burnin using as priors the posteriors from the parametrisation chains: these are the mini chains.
 
 4- combine all the post burning 10 samples from the mini chains into one big chain to be used as the posterior from the model.

Each step are described and demonstrated in more details below.

Using this method allowed us to run the big model described above in approximately 40 hours and 8GB of RAM per tree!

### Mini-chains parametrization

First we run three independent MCMC chains with the model and data described above using the consensus tree and flat priors (with a belief parameter of 0.02).
We ran these chains for 50k iterations, sampling every 500 iterations (with no burnin).

To do so, we can use the `make.mini.chains` function that creates a `mini.chains` object that contains all the information (data, model and trees) for further analysis.
 
```{r, parametrise_the_model, eval = TRUE}
## Set up the parametrising chains models on the demo data
param_MCMCglmm <- make.mini.chains(data         = trait_space,
                                   dimensions   = 1:3,
                                   tree         = consensus_tree,
                                   trait.family = "gaussian",
                                   randoms      = c("global", "clade"),
                                   residuals    = "global",
                                   priors       = 0.02,
                                   verbose      = TRUE,
                                   parameters   = list(
                                       nitt   = 50000,
                                       thin   = 500,
                                       burnin = 0))
## What is this new object?
class(param_MCMCglmm)
```

The main arguments here are:

 * `data`: the dataset as described above. If you use the phylogeny or clades as a random term, it needs to have one column called `"animal"` and another one named by the grouping factor (here `"clade"`).
 * `dimensions`: which dimensions from `data` to include. If the argument is a numeric value (like `1:3`) it automatically picks the corresponding columns that have numeric values (here `"PC1"`, `"PC2"` and `"PC3"`). However, you can also directly specify the name of the column (e.g. `c("PC1", "PC2", "PC3")` would five the same results).
 * `tree`: the tree to use. Here we use only one tree (the consensus one) but later we are going to use a tree distribution.
 * `trait.family`: which corresponds to the `family` argument in `MCMCglmm`. Note that if you specify only one family (here `"gaussian"`) it is applied to all the traits (here `"PC1"`, `"PC2"` and `"PC3"`). But you can also specify a vector of families (e.g. `c("gaussian", "poisson", "gaussian")`).
 * `randoms`: which random terms to use. Here `"global"` is the generic term for applying a random term to the whole dataset (the phylogeny) and `"clade` allows to apply another nested random terms to the elements described in the column `"clade"` in the dataset. Note that you can play around with many more options for the random terms by looking at the function manual (`?make.mini.chains`).
 * `residuals`: which residual terms to use. This is the same as the `randoms` argument. The `"global"` term is the generic term for applying the residuals to the whole dataset (traits) and no other nested term has been provided.
 * `priors`: setting up the prior. Here you can provide a list of priors in the proper `MCMCglmm` format (see below) or, as we are doing here, simply a flat prior for each term. To provide a flat prior, you just need to give the belief parameter value (here 2%) and the function will generate the correct flat priors attached to this belief.

The other arguments here are either self evident (e.g `verbose`) or the same as for `MCMCglmm` (here `parameters` is just a list of arguments with the correct names to be passed to `MCMCglmm`).

Once the mini.chain is ready, you can run it using the `run.mini.chains` function given the mini chain (`param_MCMCglmm`) and a number of replicates (here 3).

> This step in this example should take anywhere around 1 to 5 minutes.

```{r, eval = FALSE}
## Running the three MCMCglmm models
parametrization <- run.mini.chains(param_MCMCglmm, replicates = 3)

## Saving the model
```








From these three chains, we first extracted the three burnin periods (defined as the number of iterations when the chain reaches the median likelihood value times 1.1).
We then extracted the posterior estimates of the R-Structure, G-Structure and fixed effects (mean and covariance) (ignoring the runs from the previously estimated burnin periods) to serve as our priors for our mini-chains. 
For those values, we took the highest burnin as the overall burnin and the median of the three posteriors as the overall priors.

```{r, get_model_parameters, eval = FALSE}
## Extract the parameters from the parameter chains
estimated_params <- extract.parameters(parametrization)
```

### Running the mini-chains

We set up a mini-chain to be a MCMCglmm running with:
  1) the model described above,
  2) a random tree, and
  3) the estimated priors (with a degree of parameter belief of 5% `nu = 0.05`) to run for `nitt` generations were `nitt` is equal to the previously estimated burnin phase + 10 sampled iterations (`nitt = burnin + thin * 10`).
Each mini-chain thus provided us with 10 posterior exploitable data points.
The two main advantages of this mini-chain approach is that
  1) they are much faster to run since no diagnosis of convergence is necessary and the chains are only run for a relatively short time (which allow several chains to crash/fail without losing all the outputs); and
  2) they take into account tree uncertainty without having to run the complete `MCMCglmm` on all trees (c.f. `mulTree` @mulTree).


```{r, set_the_mini_chains, eval = FALSE}

## The thinning parameter
thin <- 500
## The number of samples per chains
samples <- 10

## Set up the mini-chains models
parametrisation_chain <- make.mini.chains(
                                data         = trait_space,
                                dimensions   = 1:3,
                                tree         = trees_list,
                                trait.family = "gaussian",
                                randoms      = c("global", "clade"),
                                residuals    = "global",
                                priors       = est_params$priors,
                                verbose      = TRUE,
                                parameters   = list(
                                    nitt   = est_params$burnin + thin * samples,
                                    thin   = thin,
                                    burnin = est_params$burnin))
```

We then run the `MCMCglmm` over 100 randomly selected trees to get an estimate of the variance-covariance matrices including phylogenetic uncertainty.

```{r, running_replicates, eval = FALSE}
## The number of replicates
n_reps <- 100

## Run the required chains
results <- run.mini.chains(mini_chains, replicates = n_reps)

## Combining the results as one big MCMC
combined_results <- combine.mini.chains(results)
```



<!-- 

#### Number of runs optimisation (TO BE DEVELOPED?)

```{r, eval = FALSE}
## Function for running one mini chain on a random tree (and saving the results)
fun.mini.chains <- function() {
    run.mini.chains(mini_chains, replicates = 1, path = "../Data/Processed/MCMC/", file.name = "mini.chains")
}
```

To make sure we reached consistent results, we run the set of N mini-chains were N was determined using the following variance optimisation algorithm.
 
 * 1. run an initial $N = 20$ chains;
 * 2. estimate the $V_{1}$, the pooled variances for each parameters in the chain (V1 is a vector of length §§§);
 * 3. update N to N = N * 1.05 and run an additional 5% chains;
 * 4. estimate $V_{2}$, the pooled variances for each parameters in the chain;
 * 5. calculate $\Delta_V$, the absolute change between $V_{1}$ and $V_{2}$ as ($\sqrt{(\frac{V_{1}}/{V_{2}} - 1)^{2}}$).
 * 6. If $\Delta_V < 0.05$ (meaning an increase of 5% of the replicates resulted in an increase of the parameters of less than 5%), the desired number of mini-chains is reached. Else, set $V_{1} = V_{2}$ and repeat from step 3.


```{r, optimised_replicates, eval = FALSE}
## The summary function

```


After reaching the desired $N$ chains, we pulled all the posterior estimates together back into a "standard" big MCMCglmm with a posterior distribution including the effective results and the phylogenetic uncertainty.

-->

## References
